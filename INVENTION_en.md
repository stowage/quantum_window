
**DEVICES AND METHODS FOR PREDICTIVE VISUALIZATION OF DYNAMIC SCENES BASED ON NEURAL NETWORK ANALYSIS OF THE EVOLUTION OF QUANTUM STATES OF LIGHT (QUANTUM WINDOW)**

**INVENTOR**

Fedoseev Sergey

### FIELD OF TECHNOLOGY

The invention relates to optical instrument-making, quantum informatics, and computer vision systems. Specifically, it concerns devices for image registration capable of reconstructing the full quantum statistics of the light field and performing probabilistic prediction of its temporal evolution using deep learning algorithms.

### LEVEL OF TECHNOLOGY

Known are digital cameras (CCD and CMOS sensors) that register the distribution of light intensity. The drawback of such devices is the loss of phase information and information about quantum correlations (compression, entanglement) at the moment of detection. A classical camera captures the result of the collapse of the wave function but not the state itself, making it impossible to analyze hidden parameters of the system's dynamics.

Known are methods of quantum tomography (Quantum Tomography), which allow reconstructing the density matrix (\(\rho\)) of the quantum state. However, existing setups are stationary laboratory stands working with single modes and are not adapted for forming multi-pixel images in real time, and they lack the ability to predict the evolution of the state.

The closest analog is the neural network method of predicting video frames (Video Prediction) used in classical computer vision. The prototype's shortcoming is working with already "collapsed" data (RGB pixels), which limits the accuracy of the prediction for chaotic and quantum-dependent systems.

### DISCLOSURE OF THE INVENTION

The technical problem of the invention is to create a device capable of visualizing the most likely state of an observed object at a specified future moment of time (\(t + \Delta t\)).

The technical result lies in the increase in the accuracy of the dynamic scene prediction by using complete quantum information (density matrices) and a neural network extrapolation of the state vector in Hilbert space up to the moment of measurement.

This result is achieved by the fact that the device contains:

1. **Matrix Sensor of Quantum States**, implemented on a balanced homodyne detector array, where each pixel measures the quadratures of the field.
2. **Reconstruction Block**, which transforms raw data into a tensor of density matrices.
3. **Neuromorphic Processor**, containing a model trained on the history of changes in quantum states and performs prediction of the density matrix at step \(\Delta t\).
4. **Projection Visualization Block**, which forms the image by reading the diagonal elements of the predicted matrix (photon number distribution).

### BRIEF DESCRIPTION OF THE DRAWINGS

*   **Fig. 1** — General functional scheme of the "Quantum Window" device.
*   **Fig. 2** — Optical scheme of one "quantum pixel" (Homodyne detector).
*   **Fig. 3** — Data structure and neural network architecture.
*   **Fig. 4** — Algorithm for reading the diagonal and forming the image.

---

### IMPLEMENTATION OF THE INVENTION

#### 1. Hardware Part

The device (Fig. 1) consists of an optical block, a signal processing block, and a display.

**Optical Block (Fig. 2)** represents a matrix of size \(N \times M\) (e.g., \(128 \times 128\)), where each cell is an independent interferometer.
Each cell contains:

*   An input for the signal beam (from the objective).
*   An input for the reference beam (Local Oscillator - LO). The reference beam is generated by an embedded laser (e.g., Nd:YAG 1064 nm) and distributed to all pixels through a system of microlenses or waveguides.
*   **Phase Modulator:** An electro-optic element (based on \(LiNbO_3\)) that changes the phase of LO over the range \(0 \dots \pi\) with high frequency (around 100 MHz) for quadrature scanning.
*   **Beam splitter 50/50:** Mixes the signal and LO.
*   **Balanced Detector:** A pair of PIN photodiodes connected in a differential circuit to suppress classical noise.

**Data Acquisition Block (DAQ):** Signals from the detectors are digitized by a multi-channel ADC with at least 14-bit resolution and a sampling rate exceeding the phase modulation frequency. A PLD (FPGA) performs primary filtering and statistical accumulation.

#### 2. Software Part and Data Processing

**State Reconstruction:**
PLD or GPU implements a linear inversion algorithm or an iterative maximum likelihood estimation (iMLE) method to transform the set of measured quadratures \((X, \theta)\) into a density matrix \(\rho\) of dimension \(D \times D\) (where \(D\) is the dimension of the Fourier space, e.g., 15).
As a result, a "quantum frame" is formed — a tensor of dimensions \((H, W, D, D)\) with complex numbers.

**Predictive Neural Network (Fig. 3):**

Uses a recurrent network architecture (e.g., ConvLSTM or 3D-Transformer).

*   **Input:** A sequence of quantum frames over time \(T_{history}\).
*   **Condition:** Scalar value of time shift \(\Delta t\) (set by the user).
*   **Training:** The network is trained on a dataset of "Quantum History Dataset," containing records of the evolution of density matrices for various physical processes. The loss function (\(Loss\)) is based on the quantum fidelity metric (\(Fidelity\)):
    \[
    Loss = 1 - \left( \text{Tr} \sqrt{\sqrt{\rho_{pred}} \rho_{real} \sqrt{\rho_{pred}}} \right)^2
    \]
    This ensures that the network learns not just the brightness change but the laws of unitary evolution of the Hamiltonian system.

**Visualization (Fig. 4):**
To display the predicted state on the screen, a transition from the quantum description to the classical one is required. The method of "diagonal reading" is used.
The diagonal elements of the density matrix \(\rho_{nn}\) correspond to the probability of finding \(n\) photons in a mode.
The intensity of the pixel \(I\) is calculated as:
\[
I_{x,y} = \sum_{n=0}^{D-1} n \cdot \rho_{nn}^{(x,y)}
\]
Where \(\rho^{(x,y)}\) is the predicted density matrix for the pixel at coordinates \((x, y)\).

---

### FORMULA OF THE INVENTION

**1.** An optoelectronic device for predictive visualization ("Quantum Window") that includes:

*   an optical system including a matrix of pixels, each of which is implemented as a homodyne detector connected to a source of coherent reference radiation and a phase modulator for measuring the quadrature components of the electromagnetic field;
*   a primary data processing block capable of reconstructing the density matrix (\(\rho\)) for each pixel based on the measured quadrature components;
*   a neural network computing module containing a trained artificial neural network model configured to receive a sequence of reconstructed density matrices and generate a predicted density matrix corresponding to the state of the field at a specified interval of time;
*   a visualization module capable of forming an image by calculating the mathematical expectation of the number of photons for each pixel based on the diagonal elements of the predicted density matrix.

**2.** The device according to item 1, **distinguished by the fact** that the neural network model is trained on a dataset representing the history of the time evolution of the quantum states of optical fields recorded by the same device.

**3.** The device according to item 1, **distinguished by the fact** that the phase modulator is implemented to cyclically change the phase of the reference radiation over a range from 0 to \(\pi\) radians at a frequency that ensures statistical collection within the exposure time of one frame.

**4.** A method of displaying a predictive image using the device according to item 1, including steps:

*   registering the quadrature components of the light field from the observed object;
*   reconstructing the density matrix for each spatial element of the image;
*   accumulating the history of changes in the density matrices in a memory buffer;
*   entering a user-defined time shift value (\(\Delta t\));
*   processing the history of changes by the neural network to obtain the predicted density matrix at the current time \(t_{current} + \Delta t\);
*   calculating the brightness of each pixel of the output image as a weighted sum of the diagonal elements of the predicted density matrix (\(\sum n \cdot \rho_{nn}\));
*   displaying the image on the screen.

**5.** The method according to item 4, **distinguished by the fact** that during visualization, non-diagonal elements of the predicted density matrix are used for color coding of phase information or the degree of quantum coherence of the predicted image.

---

### ABSTRACT

The invention relates to systems of quantum vision and artificial intelligence. The "Quantum Window" device provides visualization of the probable future state of the observed scene. The device contains a matrix of homodyne detectors that record the quantum statistics of light without completely destroying phase information during data acquisition. Based on a series of measurements, the processor reconstructs the density matrices for each pixel. A neural network, trained on the history of quantum dynamics, extrapolates the state of the density matrices to a future time interval specified by the user. The image is formed by reading the diagonal elements (photon number distribution) of the predicted matrices. The technical result is the ability to observe the dynamics of processes with a lead in real time by analyzing the hidden parameters of quantum evolution.

---

### FIG. 1. GENERAL FUNCTIONAL SCHEME OF THE DEVICE

Shows the flow of data from the photon to the display.

```text
   [OBJECT OF OBSERVATION]
           |
           | (1) Input light stream (Quantum field)
           V
  +-------------------------+
  | (2) OPTICAL SYSTEM       | <--- Objective
  +-----------+-------------+
              |
              V
  +-------------------------+       +---------------------+
  | (3) MATRIX SENSOR       | <---- | (4) LASER BLOCK     |
  |   (Homodyne array)      |       | (Local Oscillator)  |
  +-----------+-------------+       +---------------------+
              |
              | (5) Analog signals (Quadratures X_theta)
              V
  +-------------------------+
  | (6) DATA ACQUISITION    | <--- (ADC + FPGA)
  |   AND RECONSTRUCTION    |      Reconstruction of Ro
  +-----------+-------------+
              |
              | (7) Tensor stream: [Time, H, W, D, D]
              V
  +-------------------------+       +---------------------+
  | (8) NEUROPROCESSOR      | <---- | (9) INTERFACE       |
  |     (AI Prediction)     |       | TIME SHIFT INPUT    |
  +-----------+-------------+       | (Delta T)          |
              |                     +---------------------+
              | (10) Predicted Ro matrix (t + dt)
              V
  +-------------------------+
  | (11) VISUALIZATION      | <--- Diagonal reading
  +-----------+-------------+
              |
              | (12) Classical video signal (HDMI/DP)
              V
       [ (13) DISPLAY ]
```

**Legend (Explanation of Fig. 1):**

1. Incoming optical radiation.
2. Lens system.
3. Array of quantum sensors (\(128 \times 128\)).
4. Source of reference radiation (LO).
5. Differential current signals.
6. Primary processing module (Tomography Engine).
7. Digital stream of density matrices.
8. Neural network prediction module.
9. Time shift control element.
10. Data on the future state.
11. Converter "Quantum → Brightness".
12. Video signal.
13. Screen.

---

### FIG. 2. SCHEMATIC OF ONE "QUANTUM PIXEL"

Detailed view of node (3). Shows the homodyne detector structure.

```text
         (Signal Input)             (Reference Beam Input LO)
              |                              |
              V                              V
      +-------+-------+              +-------+-------+
      | (21) INPUT  |              | (22) PHASE  |
      |    APERTURE |              | MODULATOR   | <--- Control (Theta)
      +-------+-------+              +-------+-------+
              |                              |
              |                              |
              V        (23) COMBINER         V
      +----------------------------------------------+
      |       BEAM SPLITTER PLATE (50/50)            |
      +-------+------------------------------+-------+
              |                              |
              | (Beam A)                      | (Beam B)
              V                              V
      +-------+-------+              +-------+-------+
      | (24) PHOTODIODE |              | (25) PHOTODIODE |
      |      (+)       |              |      (-)       |
      +-------+-------+              +-------+-------+
              | I_1                          | I_2
              |                              |
              +-------------+----------------+
                            |
                            V
                     (26) SUBTRACTER
                     (I_diff = I1 - I2)
                            |
                            V
                    TO ADC (Quadrature X)
```

**Explanation of Fig. 2:**

21. Pixel microlens.
22. Electro-optic phase modulator (scans angle from 0 to \(\pi\)). 
23. Beam splitter.
24. Balanced PIN photodiodes.
25. -/- 
26. Current subtraction circuit (for removing classical noise and isolating the quantum signal).

---

### FIG. 3. NEURAL NETWORK ARCHITECTURE AND DATA STRUCTURE

Detailed view of node (8). Shows how the network processes history.

```text
   INPUT HISTORY TENSOR (30)
   [T_steps, H, W, D, D]
   (Sequence of density matrices)

         |     |     |
       [Ro_1][Ro_2][Ro_3] ...
         |     |     |
         V     V     V
   +-----------------------------+
   | (31) ENCODER CODE             |
   |    (3D-Conv Layers)          |
   +-------------+---------------+
                 |
                 V
         (32) LATENT STATE (Latent Vector Z)
                 +
                 | <---- (33) TIME VECTOR (Delta t)
                 V
   +-----------------------------+
   | (34) PREDICTOR (CORE)        | <--- Hamiltonian evolution modeling
   | (ConvLSTM / Transformer)     |      H_eff * t
   +-------------+---------------+
                 |
                 V
   +-----------------------------+
   | (35) DECODER (RECONSTRUCTION)| 
   | Layers                       |
   +-------------+---------------+
                 |
                 V
         OUTPUT TENSOR (36)
         [H, W, D, D]
         (Predicted future matrix Ro_future)
```

**Explanation of Fig. 3:**

30. Input data stack (history).
31. Feature extraction convolutional layers.
32. Compressed representation of dynamics.
33. User input of time parameter.
34. Recurrent core (computes evolution).
35. Dimensionality reconstruction layers.
36. Result (Density matrix of the future).

---

### FIG. 4. VISUALIZATION ALGORITHM (DIAGONAL READING)

Detailed view of node (11). Mathematics of the transition from quantum to pixels.

```text
   (40) PREDICTED DENSITY MATRIX (Ro)
   (For one image pixel)

      |0>    |1>    |2>    ...   |N>
   +------+------+------+      ------+
|0>| P_00 |  .   |  .   | ...  |  .  |
   +------+------+------+      ------+
|1>|  .   | P_11 |  .   | ...  |  .  |   <--- (41) PRINCIPAL DIAGONAL
   +------+------+------+      ------+        (Probabilities Pn)
|2>|  .   |  .   | P_22 | ...  |  .  |
   +------+------+------+      ------+
 :    :      :      :     \.      :
   +------+------+------+      ------+
|N>|  .   |  .   |  .   | ...  | P_NN|
   +------+------+------+      ------+

                 |
                 V
      (42) DIAGONAL EXTRACTION
      Vect = [P_00, P_11, P_22, ..., P_NN]

                 |
                 V
      (43) WEIGHTED SUMMATION
      Intensity = (0 * P_00) + (1 * P_11) + (2 * P_22) + ...

                 |
                 V
      (44) GAMMA-CORRECTION
      Pixel_Value = (Intensity ^ 1/2.2) * 255

                 |
                 V
         (45) ON SCREEN
```

**Explanation of Fig. 4:**

40. Density matrix of size \(15 \times 15\) (complex numbers). 
41. Diagonal elements (real numbers, photon number probabilities). 
42. Probability vector. 
43. Calculation of the expected value \(\langle n \rangle\). 
44. Adaptation for human eye. 
45. Final pixel brightness signal.

